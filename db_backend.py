# db_backend.py

import sqlite3
import pandas as pd
import tempfile
import os
import csv
import time
import re
import traceback
import subprocess
import platform


class SQLiteBackend:
    """SQLiteã‚’ä½¿ã£ãŸé«˜é€Ÿãƒ‡ãƒ¼ã‚¿å‡¦ç†ï¼ˆUIçµ±åˆç‰ˆï¼‰"""

    def __init__(self, app_instance):
        self.app = app_instance
        self.db_file = tempfile.mktemp(suffix='.db')
        self.conn = sqlite3.connect(self.db_file, check_same_thread=False)
        self.table_name = 'csv_data'
        self.cancelled = False
        self.header = []
        self.sort_info = None
        self.encoding = 'utf-8'

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šã®ãŸã‚ã®PRAGMAè¨­å®šï¼ˆå¤§å¹…å¼·åŒ–ï¼‰
        self.conn.execute("PRAGMA journal_mode=WAL")
        self.conn.execute("PRAGMA synchronous=NORMAL")
        self.conn.execute("PRAGMA cache_size=-256000")  # 256MB cacheï¼ˆ4å€å¢—å¼·ï¼‰
        self.conn.execute("PRAGMA mmap_size=536870912")  # 512MB memory mapping
        self.conn.execute("PRAGMA temp_store=MEMORY")
        self.conn.execute("PRAGMA optimize")  # è‡ªå‹•æœ€é©åŒ–

    def import_csv_with_progress(self, filepath, encoding='utf-8', delimiter=',', progress_callback=None):
        self.cancelled = False
        self.encoding = encoding

        try:
            # Step 1: è¡Œæ•°ã®ã‚«ã‚¦ãƒ³ãƒˆ
            if progress_callback:
                progress_callback("ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèªä¸­...", 0, 100)
            
            total_rows = self._fast_line_count(filepath)
            
            if self.cancelled:
                return None, 0
            
            if total_rows <= 0:
                return None, 0

            # Step 2: CSVã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            if progress_callback:
                progress_callback(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æº–å‚™ä¸­... (å…¨{total_rows:,}è¡Œ)", 5, 100)
            
            df_sample = pd.read_csv(filepath, nrows=0, encoding=encoding, sep=delimiter)
            columns = df_sample.columns.tolist()
            self._create_table(columns)
            self.header = columns

            chunk_size = 50000
            processed_rows = 0
            
            reader = pd.read_csv(filepath, chunksize=chunk_size, encoding=encoding, dtype=str, sep=delimiter, on_bad_lines='skip')

            for chunk in reader:
                if self.cancelled:
                    break
                
                chunk.to_sql(self.table_name, self.conn, if_exists='append', index=False)
                processed_rows += len(chunk)
                
                if progress_callback:
                    percentage = (processed_rows / total_rows * 90) if total_rows > 0 else 0
                    status_text = f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆä¸­... ({percentage:.1f}%)"
                    progress_callback(status_text, 5 + int(percentage * 0.95), 100)

            if self.cancelled:
                self.close()
                return None, 0

            # Step 3: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®ä½œæˆ
            if progress_callback:
                progress_callback("ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ä¸­... (é«˜é€ŸåŒ–å‡¦ç†)", 95, 100)
            
            for i, col in enumerate(columns):
                if self.cancelled:
                    break
                try:
                    # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†ã‚’f-stringå¤–ã§å®Ÿè¡Œ
                    escaped_col = col.replace('"', '""')
                    index_name = f'idx_{i}'  # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åã‚’ç°¡ç´ åŒ–
                    self.conn.execute(f'CREATE INDEX IF NOT EXISTS "{index_name}" ON {self.table_name}("{escaped_col}")')
                except sqlite3.OperationalError as e:
                    print(f"Could not create index on column '{col}': {e}")
                
                if progress_callback:
                    col_percentage = ((i + 1) / len(columns)) * 5
                    progress_callback(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ§‹ç¯‰ä¸­... ({col})", 95 + int(col_percentage), 100)

            if self.cancelled:
                self.close()
                return None, 0

            self.conn.commit()
            return columns, processed_rows

        except Exception as e:
            self.close()
            raise e

    def _fast_line_count(self, filepath):
        """OSãƒã‚¤ãƒ†ã‚£ãƒ–ã‚³ãƒãƒ³ãƒ‰ã‚’ä½¿ã£ãŸé«˜é€Ÿè¡Œæ•°ã‚«ã‚¦ãƒ³ãƒˆ"""
        try:
            if platform.system() == 'Windows':
                result = subprocess.run(
                    ['powershell', '-Command', f'(Get-Content -LiteralPath "{filepath}" | Measure-Object -Line).Lines'],
                    capture_output=True, text=True, check=True,
                    creationflags=subprocess.CREATE_NO_WINDOW
                )
                return int(result.stdout.strip()) - 1 if int(result.stdout.strip()) > 0 else 0
            else:
                # Unixç³»ã¯wcã‚³ãƒãƒ³ãƒ‰
                result = subprocess.run(
                    ['wc', '-l', filepath],
                    capture_output=True, text=True, check=True
                )
                return int(result.stdout.split()[0]) - 1
        except (subprocess.CalledProcessError, FileNotFoundError, ValueError) as e:
            print(f"WARNING: Fast line count failed using OS command: {e}. Falling back to Python.")
            try:
                with open(filepath, 'r', encoding=self.encoding, errors='ignore') as f:
                    count = -1
                    buf_size = 1024 * 1024
                    while True:
                        data = f.read(buf_size)
                        if not data:
                            break
                        count += data.count('\n')
                    return count if count >= 0 else 0
            except Exception as e_fallback:
                print(f"ERROR: Fallback line count also failed: {e_fallback}")
                return 0

    def _create_table(self, columns):
        """ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆæ™‚ã®åˆ—åã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã‚’ã‚ˆã‚Šå …ç‰¢ã«"""
        # f-stringå¤–ã§ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†
        sanitized_column_defs = []
        for col in columns:
            sanitized_col_name = col.replace('"', '""')
            sanitized_column_defs.append(f'"{sanitized_col_name}" TEXT')
        
        column_defs_str = ", ".join(sanitized_column_defs)
        create_sql = f"CREATE TABLE {self.table_name} ({column_defs_str})"
        self.conn.execute(f"DROP TABLE IF EXISTS {self.table_name}")
        self.conn.execute(create_sql)

    def _create_indexes(self, columns):
        for col in columns:
            try:
                escaped_col = col.replace('"', '""')
                self.conn.execute(f'CREATE INDEX IF NOT EXISTS "idx_{escaped_col}" ON {self.table_name}("{escaped_col}")')
            except sqlite3.OperationalError as e:
                print(f"Could not create index on column '{col}': {e}")

    def set_sort_order(self, column_name, order):
        """UIã‹ã‚‰ã®ã‚½ãƒ¼ãƒˆæŒ‡ç¤ºã‚’å—ã‘å–ã‚Šã€çŠ¶æ…‹ã‚’ä¿å­˜ã™ã‚‹"""
        if column_name is None:
            self.sort_info = None
        else:
            self.sort_info = {'column': column_name, 'order': order}

    def search(self, search_term, columns=None, case_sensitive=True, is_regex=False):
        """æœ€é©åŒ–ã•ã‚ŒãŸè¤‡æ•°åˆ—æ¤œç´¢"""
        print(f"DEBUG: SQLite search - term: '{search_term}', columns: {columns}, case_sensitive: {case_sensitive}, is_regex: {is_regex}")
        
        # ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼ï¼ˆä¸€æ™‚çš„ã«æœ‰åŠ¹åŒ–ã—ã¦ç¢ºèªå¾Œã€ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã¾ãŸã¯å‰Šé™¤æ¨å¥¨ï¼‰
        # self.debug_data_verification() 
        
        if not columns:
            columns = self.header
            print(f"DEBUG: æ¤œç´¢å¯¾è±¡åˆ—æ•°: {len(columns)}")
        
        # åˆ—æ•°ã«ã‚ˆã‚‹å‡¦ç†æ–¹æ³•ã®æœ€é©åŒ–
        if len(columns) > 20:
            chunk_size = 10000  # å¤§é‡åˆ—ã®å ´åˆã¯ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’èª¿æ•´
        else:
            chunk_size = 50000
        
        if is_regex:
            return self._search_regex_optimized(search_term, columns, case_sensitive, chunk_size)
        else:
            return self._search_like_optimized(search_term, columns, case_sensitive)

    def _search_like_optimized(self, search_term, columns, case_sensitive):
        """LIKEæ¤œç´¢ã®æœ€é©åŒ–ï¼ˆUNION ALLä½¿ç”¨ï¼‰"""
        search_results = []
        like_term = f'%{search_term}%'
        
        # è¤‡æ•°åˆ—ã‚’UNION ALLã§åŠ¹ç‡çš„ã«æ¤œç´¢
        union_queries = []
        params = []
        
        for col_name in columns:
            if col_name not in self.header:
                continue
            
            col_idx = self.header.index(col_name)
            escaped_col_name = col_name.replace('"', '""')
            
            if case_sensitive:
                condition = f'"{escaped_col_name}" LIKE ?'
            else:
                condition = f'LOWER("{escaped_col_name}") LIKE LOWER(?)'
            
            union_queries.append(f"""
                SELECT rowid - 1 as row_idx, {col_idx} as col_idx
                FROM {self.table_name}
                WHERE {condition}
            """)
            params.append(like_term)
        
        if union_queries:
            full_query = " UNION ALL ".join(union_queries)
            try:
                cursor = self.conn.execute(full_query, params)
                search_results = [(row[0], row[1]) for row in cursor]
            except sqlite3.OperationalError as e:
                print(f"ERROR: è¤‡æ•°åˆ—æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
                return self._search_like_fallback(search_term, columns, case_sensitive)
        
        return search_results

    def _search_like_fallback(self, search_term, columns, case_sensitive):
        """UNION ALLãŒå¤±æ•—ã—ãŸå ´åˆã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†ï¼ˆæ—¢å­˜ã®å˜ä¸€åˆ—æ¤œç´¢ã‚’ãƒ«ãƒ¼ãƒ—ï¼‰"""
        search_results = []
        like_term = f'%{search_term}%'
        
        for col_name in columns:
            if col_name not in self.header:
                continue
            
            escaped_col_name = col_name.replace('"', '""')
            
            if case_sensitive:
                query = f'SELECT rowid - 1 FROM {self.table_name} WHERE "{escaped_col_name}" LIKE ?'
                params = [like_term]
            else:
                query = f'SELECT rowid - 1 FROM {self.table_name} WHERE LOWER("{escaped_col_name}") LIKE LOWER(?)'
                params = [like_term]
            
            try:
                cursor = self.conn.execute(query, params)
                col_idx = self.header.index(col_name) if col_name in self.header else 0 # åˆ—åã‹ã‚‰åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
                for row in cursor:
                    search_results.append((row[0], col_idx)) # (row_index, column_index)å½¢å¼ã§è¿½åŠ 
            except sqlite3.OperationalError as e:
                print(f"ERROR: åˆ— '{col_name}' ã®æ¤œç´¢ã‚¨ãƒ©ãƒ¼ (ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯): {e}")
        return search_results

    def _search_regex_optimized(self, search_term, columns, case_sensitive, chunk_size):
        """æ­£è¦è¡¨ç¾æ¤œç´¢ã®æœ€é©åŒ–ï¼ˆPandasãƒãƒ£ãƒ³ã‚¯å‡¦ç†ï¼‰"""
        search_results = []
        total_rows = self.get_total_rows()

        import re
        try:
            flags = 0
            if not case_sensitive:
                flags |= re.IGNORECASE
            if '^' in search_term or '$' in search_term:
                flags |= re.MULTILINE
            pattern = re.compile(search_term, flags)
        except re.error as e:
            print(f"æ­£è¦è¡¨ç¾ã‚¨ãƒ©ãƒ¼: {e}")
            return []
        
        valid_target_columns = [col for col in columns if col in self.header]
        if not valid_target_columns:
            print("WARNING: æ¤œç´¢å¯¾è±¡ã®æœ‰åŠ¹ãªåˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return []

        # ãƒãƒ£ãƒ³ã‚¯ã”ã¨ã«ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€Pandasã§æ­£è¦è¡¨ç¾æ¤œç´¢
        for offset in range(0, total_rows, chunk_size):
            if hasattr(self, 'cancelled') and self.cancelled:
                break
            
            limit = min(chunk_size, total_rows - offset)
            
            # æ¤œç´¢å¯¾è±¡åˆ—ã¨rowidã®ã¿ã‚’èª­ã¿è¾¼ã‚€ã‚¯ã‚¨ãƒªã‚’ç”Ÿæˆ
            select_cols_quoted = []
            for col in valid_target_columns:
                escaped_col = col.replace('"', '""')
                select_cols_quoted.append(f'"{escaped_col}"')
            
            # SQLã‚¯ã‚¨ãƒª
            query = f'''
                SELECT rowid, {", ".join(select_cols_quoted)}
                FROM {self.table_name}
                LIMIT {limit} OFFSET {offset}
            '''
            
            chunk_df = pd.read_sql_query(query, self.conn)
            if chunk_df.empty:
                continue
            
            # Pandasã®str.containsã§é«˜é€Ÿæ­£è¦è¡¨ç¾ãƒãƒƒãƒãƒ³ã‚°
            for col_name in valid_target_columns:
                if col_name in chunk_df.columns:
                    matched_mask = chunk_df[col_name].astype(str).str.contains(pattern, na=False, regex=True)
                    
                    if matched_mask.any():
                        for idx in chunk_df[matched_mask].index:
                            rowid = chunk_df.loc[idx, 'rowid']
                            # åˆ—åã‹ã‚‰åˆ—ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’æ­£ç¢ºã«å–å¾—
                            col_idx = self.header.index(col_name) if col_name in self.header else 0
                            search_results.append((rowid - 1, col_idx)) # rowidã¯1ã‹ã‚‰å§‹ã¾ã‚‹ãŸã‚-1ã™ã‚‹
            
            # é€²æ—é€šçŸ¥
            if hasattr(self, 'app') and hasattr(self.app, 'async_manager'):
                progress_value = min(100, int(((offset + limit) / total_rows) * 100))
                status = f"æ­£è¦è¡¨ç¾æ¤œç´¢ä¸­... ({offset + limit:,}/{total_rows:,}è¡Œ)"
                try:
                    self.app.async_manager.task_progress.emit(status, progress_value, 100)
                except:
                    pass
                
        print(f"DEBUG: æ¤œç´¢å®Œäº† - åˆè¨ˆ {len(search_results)} ä»¶")
        return search_results

    def execute_replace_all_in_db(self, settings):
        """ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã«ã‚ˆã‚‹é«˜é€Ÿç½®æ›ï¼ˆæœ€é©åŒ–ç‰ˆï¼‰"""
        import pandas as pd
        import re
        
        search_term = settings["search_term"]
        replace_term = settings["replace_term"]
        target_columns = settings["target_columns"]
        is_regex = settings["is_regex"]
        is_case_sensitive = settings["is_case_sensitive"]
        
        print(f"DEBUG: execute_replace_all_in_db called with settings: {settings}")
        
        if not search_term or not target_columns:
            return False, 0, []
        
        # æ­£è¦è¡¨ç¾ãƒ‘ã‚¿ãƒ¼ãƒ³ã®äº‹å‰ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ï¼ˆé‡è¦ãªæœ€é©åŒ–ï¼‰
        try:
            if is_regex:
                flags = 0
                if not is_case_sensitive:
                    flags |= re.IGNORECASE
                if '^' in search_term or '$' in search_term:
                    flags |= re.MULTILINE
                pattern = re.compile(search_term, flags)
            else:
                pattern = re.compile(re.escape(search_term), 
                                     0 if is_case_sensitive else re.IGNORECASE)
        except re.error as e:
            print(f"æ­£è¦è¡¨ç¾ã‚¨ãƒ©ãƒ¼: {e}")
            return False, 0, []
        
        total_rows = self.get_total_rows()
        total_updated_count = 0
        chunk_size = 50000
        
        cursor = self.conn.cursor()
        
        # ğŸ”¥ è¿½åŠ : Undoç”¨ã®å¤‰æ›´å±¥æ­´ã‚’åé›†
        all_changes_for_undo = []

        try:
            cursor.execute('BEGIN TRANSACTION')
            
            # ãƒãƒ£ãƒ³ã‚¯ã”ã«å‡¦ç†
            for offset in range(0, total_rows, chunk_size):
                # ã‚­ãƒ£ãƒ³ã‚»ãƒ«å‡¦ç†
                if hasattr(self, 'cancelled') and self.cancelled:
                    break
                
                # ãƒãƒ£ãƒ³ã‚¯ã‚’åŠ¹ç‡çš„ã«èª­ã¿è¾¼ã¿
                limit = min(chunk_size, total_rows - offset)
                
                escaped_select_cols = []
                for col in target_columns:
                    escaped_col = col.replace('"', '""')
                    escaped_select_cols.append(f'"{escaped_col}"')
                
                select_cols = ['rowid'] + escaped_select_cols
                
                query = f'''
                    SELECT {", ".join(select_cols)}
                    FROM {self.table_name}
                    LIMIT {limit} OFFSET {offset}
                '''
                
                chunk_df = pd.read_sql_query(query, self.conn)
                if chunk_df.empty:
                    continue
                
                # ğŸ”¥ é‡è¦: rowidã‚’ä¸€æ„ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã—ã¦è¨­å®š
                chunk_df.set_index('rowid', inplace=True)
                
                # Pandasã§è¶…é«˜é€Ÿå‡¦ç†
                changes_in_chunk = []
                
                for col in target_columns:
                    if col in chunk_df.columns:
                        # ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã•ã‚ŒãŸç½®æ›å‡¦ç†
                        old_values = chunk_df[col].astype(str).fillna('')
                        new_values = old_values.str.replace(pattern, replace_term, regex=True)
                        
                        # å¤‰æ›´ãŒã‚ã£ãŸè¡Œã®ã¿ã‚’ç‰¹å®š
                        changed_mask = old_values != new_values
                        
                        if changed_mask.any():
                            # ğŸ”¥ ä¿®æ­£: ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ï¼ˆrowidï¼‰ã‚’ç›´æ¥ä½¿ç”¨
                            for rowid in chunk_df[changed_mask].index:
                                new_value = str(new_values.loc[rowid])
                                old_value = str(old_values.loc[rowid]) # old_values Seriesã¯rowidã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã—ã¦æŒã£ã¦ã„ã‚‹ã¯ãš
                                
                                # ğŸ”¥ è¿½åŠ : Undoç”¨ãƒ‡ãƒ¼ã‚¿ã®åé›†
                                all_changes_for_undo.append({
                                    'item': str(rowid - 1),  # SQLiteã®rowidã¯1ã‹ã‚‰å§‹ã¾ã‚‹ãŸã‚-1ã™ã‚‹
                                    'column': col,
                                    'old': str(old_value),
                                    'new': str(new_value)
                                })

                                changes_in_chunk.append((new_value, rowid, col))
                                print(f"DEBUG: ç½®æ›æ¤œå‡º - rowid: {rowid} (type: {type(rowid)}), "
                                      f"col: {col}, old: '{old_value}', new: '{new_value}'")
                
                # ãƒãƒƒãƒã§åŠ¹ç‡çš„ã«æ›´æ–°
                if changes_in_chunk:
                    # åˆ—ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦ä¸€æ‹¬æ›´æ–°
                    by_column = {}
                    for new_value_item, rowid_item, col_item in changes_in_chunk:
                        if col_item not in by_column:
                            by_column[col_item] = []
                        safe_new_value = str(new_value_item)
                        safe_rowid = int(rowid_item)
                        by_column[col_item].append((safe_new_value, safe_rowid))
                    
                    # executemanyã§é«˜é€Ÿãƒãƒƒãƒæ›´æ–°
                    for col_to_update, updates_list in by_column.items():
                        escaped_col = col_to_update.replace('"', '""')
                        sql = f'UPDATE {self.table_name} SET "{escaped_col}" = ? WHERE rowid = ?'
                        
                        print(f"DEBUG: SQLå®Ÿè¡Œæº–å‚™ - åˆ—: {col_to_update}, æ›´æ–°ä»¶æ•°: {len(updates_list)}")
                        
                        try:
                            cursor.executemany(sql, updates_list)
                            print(f"DEBUG: SQLå®Ÿè¡ŒæˆåŠŸ - åˆ—: {col_to_update}")
                        except Exception as sql_error:
                            print(f"ERROR: SQLå®Ÿè¡Œå¤±æ•— - åˆ—: {col_to_update}, ã‚¨ãƒ©ãƒ¼: {sql_error}")
                            raise
                    
                    total_updated_count += len(changes_in_chunk)
                
                # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°
                if hasattr(self, 'app'):
                    progress = min(100, int(((offset + limit) / total_rows) * 100))
                    status = f"é«˜é€Ÿå‡¦ç†ä¸­... ({offset + limit:,}/{total_rows:,}è¡Œ)"
                    try:
                        self.app.async_manager.task_progress.emit(status, progress, 100)
                    except:
                        pass
            
            self.conn.commit()
            print(f"DEBUG: ç½®æ›å®Œäº† - åˆè¨ˆ {total_updated_count} ä»¶ã‚’æ›´æ–°")
            
            # ğŸ”¥ ä¿®æ­£: å¤‰æ›´å±¥æ­´ã‚‚è¿”ã™
            return True, total_updated_count, all_changes_for_undo
            
        except Exception as e:
            self.conn.rollback()
            print(f"ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            # ğŸ”¥ ä¿®æ­£: å¤‰æ›´å±¥æ­´ã‚‚è¿”ã™ã‚ˆã†ã«å¤‰æ›´
            return False, 0, []

    def update_cells(self, changes: list):
        """ãƒãƒƒãƒæ›´æ–°ã«ã‚ˆã‚‹é«˜é€ŸåŒ–ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–ç‰ˆï¼‰"""
        if not changes:
            return
        
        cursor = self.conn.cursor()
        try:
            cursor.execute('BEGIN TRANSACTION')
            
            # åˆ—ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦executemanyã§ä¸€æ‹¬æ›´æ–°
            updates_by_column = {}
            for change in changes:
                col_name = change['col_name']
                # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ–: åˆ—åãŒæ­£å½“ã‹ãƒã‚§ãƒƒã‚¯
                if col_name not in self.header:
                    print(f"WARNING: ä¸æ­£ãªåˆ—å '{col_name}' ãŒæ¤œå‡ºã•ã‚Œã¾ã—ãŸã€‚ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
                    continue
                
                if col_name not in updates_by_column:
                    updates_by_column[col_name] = []
                updates_by_column[col_name].append((change['new_value'], change['row_idx'] + 1))

            for col_name, params_list in updates_by_column.items():
                # SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–ï¼šåˆ—åã‚¨ã‚¹ã‚±ãƒ¼ãƒ— + ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼
                escaped_col_name = col_name.replace('"', '""')
                sql = f'UPDATE "{self.table_name}" SET "{escaped_col_name}" = ? WHERE rowid = ?'
                cursor.executemany(sql, params_list)

            self.conn.commit()
        except Exception as e:
            self.conn.rollback()
            print(f"DB update failed: {e}")
            raise

    def get_rows_by_ids(self, indices):
        if not indices:
            return pd.DataFrame(columns=self.header)

        unique_indices = sorted(list(set(indices)))
        params = [i + 1 for i in unique_indices]
        placeholders = ','.join('?' * len(params))

        # f-stringå¤–ã§ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†
        select_cols = []
        for h in self.header:
            escaped_h = h.replace('"', '""')
            select_cols.append(f'"{escaped_h}"')

        select_cols_str = ", ".join(select_cols)
        query = f'SELECT rowid, {select_cols_str} FROM {self.table_name} WHERE rowid IN ({placeholders})'

        df = pd.read_sql_query(query, self.conn, params=params)

        if df.empty:
            return pd.DataFrame(columns=self.header)

        df.set_index(df['rowid'] - 1, inplace=True)
        df.drop(columns=['rowid'], inplace=True)

        if set(self.header).issubset(df.columns):
            df = df[self.header]

        return df.reindex(indices)

    def get_all_indices(self):
        query = f"SELECT rowid - 1 FROM {self.table_name}"
        if self.sort_info and self.sort_info['column'] in self.header:
            from PySide6.QtCore import Qt
            escaped_col = self.sort_info['column'].replace('"', '""')
            order_str = "ASC" if self.sort_info['order'] == Qt.AscendingOrder else "DESC"
            query += f' ORDER BY "{escaped_col}" {order_str}'
        else:
            query += " ORDER BY rowid" # ORDER BY BY -> ORDER BY ã«ä¿®æ­£

        cursor = self.conn.execute(query)
        return [row[0] for row in cursor]

    def get_total_rows(self):
        try:
            return self.conn.execute(f"SELECT COUNT(*) FROM {self.table_name}").fetchone()[0]
        except (sqlite3.OperationalError, IndexError):
            return 0

    def insert_rows(self, row_pos, count, headers):
        cursor = self.conn.cursor()
        try:
            cursor.execute('BEGIN TRANSACTION')

            # f-stringå¤–ã§ã‚¨scapeå‡¦ç†
            header_cols_quoted = []
            for h in headers:
                escaped_h = h.replace('"', '""')
                header_cols_quoted.append(f'"{escaped_h}"')

            placeholders = ','.join(['?'] * len(headers))
            header_cols_str = ",".join(header_cols_quoted)
            sql = f'INSERT INTO "{self.table_name}" ({header_cols_str}) VALUES ({placeholders})'

            for _ in range(count):
                cursor.execute(sql, [""] * len(headers))

            self.conn.commit()
            return True
        except Exception as e:
            self.conn.rollback()
            print(f"DB insert_rows failed: {e}")
            raise

    def remove_rows(self, row_indices):
        if not row_indices:
            return False
        cursor = self.conn.cursor()
        try:
            cursor.execute('BEGIN TRANSACTION')
            rowids_to_delete = [idx + 1 for idx in row_indices]
            placeholders = ','.join('?' * len(rowids_to_delete))
            sql = f'DELETE FROM "{self.table_name}" WHERE rowid IN ({placeholders})'
            cursor.execute(sql, rowids_to_delete)
            self.conn.commit()
            return True
        except Exception as e:
            self.conn.rollback()
            print(f"DB remove_rows failed: {e}")
            raise

    def recreate_table_with_new_columns(self, new_headers: list, old_headers_order: list, progress_callback=None):
        """ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã‚’å†ä½œæˆï¼ˆåˆ—ã®è¿½åŠ ãƒ»å‰Šé™¤ç”¨ï¼‰"""
        temp_table_name = "temp_csv_data_rebuild"

        cursor = self.conn.cursor()
        try:
            cursor.execute('BEGIN TRANSACTION')

            # æ–°ã—ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã®åˆ—å®šç¾©
            new_column_defs = []
            for col in new_headers:
                escaped_col = col.replace('"', '""')
                new_column_defs.append(f'"{escaped_col}" TEXT')

            column_defs_str = ", ".join(new_column_defs)
            create_temp_sql = f"CREATE TABLE {temp_table_name} ({column_defs_str})"
            cursor.execute(f"DROP TABLE IF EXISTS {temp_table_name}")
            cursor.execute(create_temp_sql)

            # SELECTæ–‡ã®åˆ—ãƒªã‚¹ãƒˆä½œæˆ
            select_columns = []
            for h in new_headers:
                escaped_h = h.replace('"', '""')
                if h in old_headers_order:
                    select_columns.append(f'"{escaped_h}"')
                else:
                    # format()ãƒ¡ã‚½ãƒƒãƒ‰ã‚’ä½¿ç”¨ã—ã¦ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã®å•é¡Œã‚’å›é¿
                    select_columns.append("'' AS \"{}\"".format(escaped_h))

            total_rows = self.get_total_rows()

            if total_rows > 0:
                select_columns_str = ", ".join(select_columns)
                select_from_old_table_sql = f"SELECT {select_columns_str} FROM {self.table_name}"

                # INSERTæ–‡ã®åˆ—ãƒªã‚¹ãƒˆ
                insert_columns = []
                for h in new_headers:
                    escaped_h = h.replace('"', '""')
                    insert_columns.append(f'"{escaped_h}"')

                insert_columns_str = ", ".join(insert_columns)
                insert_sql = f'INSERT INTO {temp_table_name} ({insert_columns_str}) {select_from_old_table_sql}'
                cursor.execute(insert_sql)

                if progress_callback:
                    progress_callback(f"ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å†æ§‹ç¯‰ä¸­...", 90, 100)

            cursor.execute(f"DROP TABLE IF EXISTS {self.table_name}")
            cursor.execute(f"ALTER TABLE {temp_table_name} RENAME TO {self.table_name}")
            self.header = new_headers

            # æ–°ã—ã„ãƒ†ãƒ¼ãƒ–ãƒ«ã«ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†ä½œæˆ
            if progress_callback:
                progress_callback(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰ä¸­...", 95, 100)

            for i, col in enumerate(new_headers):
                if self.cancelled:
                    break
                try:
                    escaped_col = col.replace('"', '""')
                    index_name = f'idx_{i}'  # ç°¡ç´ åŒ–ã•ã‚ŒãŸã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å
                    self.conn.execute(f'CREATE INDEX IF NOT EXISTS "{index_name}" ON {self.table_name}("{escaped_col}")')
                except sqlite3.OperationalError as e:
                    print(f"Could not create index on column '{col}': {e}")

                if progress_callback:
                    col_percentage = ((i + 1) / len(new_headers)) * 5
                    progress_callback(f"ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å†æ§‹ç¯‰ä¸­... ({col})", 95 + int(col_percentage), 100)

            self.conn.commit()
            return True

        except Exception as e:
            self.conn.rollback()
            print(f"DB recreate_table_with_new_columns failed: {e}")
            raise

    def add_column_fast(self, column_name, default_value=''):
        """ALTER TABLEã‚’ä½¿ã£ãŸé«˜é€Ÿãªåˆ—è¿½åŠ """
        try:
            escaped_col_name = column_name.replace('"', '""')
            self.conn.execute(
                f'ALTER TABLE {self.table_name} ADD COLUMN "{escaped_col_name}" TEXT DEFAULT ? ',
                (default_value,)
            )
            self.header.append(column_name)
            self.conn.commit()
            return True
        except sqlite3.OperationalError as e:
            print(f"åˆ—è¿½åŠ ã‚¨ãƒ©ãƒ¼: {e}")
            self.conn.rollback()
            return False

    def insert_column(self, col_name, col_pos, new_full_headers):
        old_headers_order = list(self.header)
        return self.recreate_table_with_new_columns(new_full_headers, old_headers_order, progress_callback=None)

    def delete_columns(self, col_names_to_delete: list, new_full_headers: list):
        old_headers_order = list(self.header)
        return self.recreate_table_with_new_columns(new_full_headers, old_headers_order, progress_callback=None)

    def execute_replace_from_file_in_db(self, params, progress_callback=None):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã§ç›´æ¥ã€ãƒ•ã‚¡ã‚¤ãƒ«å‚ç…§ç½®æ›ã‚’å®Ÿè¡Œã™ã‚‹ã€‚"""
        
        lookup_filepath = params['lookup_filepath']
        lookup_encoding = params['lookup_file_encoding']
        target_col = params['target_col']
        lookup_key_col = params['lookup_key_col']
        replace_val_col = params['replace_val_col']

        cursor = self.conn.cursor()
        try:
            # 1. å‚ç…§ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            lookup_dict = {}
            with open(lookup_filepath, 'r', encoding=lookup_encoding, errors='ignore') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    key = row.get(lookup_key_col)
                    val = row.get(replace_val_col)
                    if key is not None and val is not None:
                        processed_key = key.strip().lower()
                        if processed_key not in lookup_dict:
                            lookup_dict[processed_key] = val

            if not lookup_dict:
                return True, [], 0

            # 2. æœ¬ä½“ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰æ›´æ–°å¯¾è±¡ã®è¡Œã‚’ç‰¹å®š
            update_targets = []
            read_cursor = self.conn.cursor()
            escaped_target_col = target_col.replace('"', '""')
            query = f'SELECT rowid, "{escaped_target_col}" FROM "{self.table_name}"'
            read_cursor.execute(query)

            total_rows = self.get_total_rows()
            processed_rows = 0

            while True:
                rows_chunk = read_cursor.fetchmany(10000)
                if not rows_chunk:
                    break

                for rowid, cell_value in rows_chunk:
                    if cell_value is not None:
                        processed_cell = str(cell_value).strip().lower()
                        if processed_cell in lookup_dict:
                            new_value = lookup_dict[processed_cell]
                            if str(cell_value) != new_value:
                                update_targets.append((new_value, rowid))

                processed_rows += len(rows_chunk)
                if progress_callback:
                    progress_callback("æ›´æ–°å¯¾è±¡ã‚’æ¤œç´¢ä¸­...", processed_rows, total_rows)

            if not update_targets:
                return True, [], 0

            # 3. ç‰¹å®šã—ãŸè¡Œã‚’ä¸€æ‹¬ã§æ›´æ–°
            if progress_callback:
                progress_callback("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ›´æ–°ä¸­...", 0, len(update_targets))

            cursor.execute('BEGIN TRANSACTION')
            
            # å®Œå…¨ãªSQLæ–‡ã‚’æ§‹ç¯‰
            update_sql = f'UPDATE "{self.table_name}" SET "{escaped_target_col}" = ? WHERE rowid = ?'
            
            total_updated_count = 0
            for i, (new_value, rowid) in enumerate(update_targets):
                cursor.execute(update_sql, (new_value, rowid))
                total_updated_count += 1
                
                if i % 1000 == 0 and progress_callback:
                    progress_callback("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ›´æ–°ä¸­...", i, len(update_targets))

            self.conn.commit()
            return True, [], total_updated_count

        except Exception as e:
            self.conn.rollback()
            print(f"DB execute_replace_from_file_in_db failed: {e}")
            return False, 0
            
    # å®Œå…¨å‰Šé™¤ï¼šä»¥ä¸‹ã®é–¢æ•°ã¯å‰Šé™¤ã—ã¦ãã ã•ã„
    # def regexp_match(pattern_str, string):
    #     if string is None:
    #         return False
    #     try:
    #         if len(string) > 10000:
    #             return False
    #         return bool(re.search(pattern_str, string, flags))
    #     except Exception as e:
    #         print(f"WARNING: æ­£è¦è¡¨ç¾ãƒãƒƒãƒã‚¨ãƒ©ãƒ¼: {e}")
    #         return False
    # self.conn.create_function("REGEXP_MATCH", 2, regexp_match) # ã“ã®è¡Œã‚‚å‰Šé™¤

    def close(self):
        """ãƒªã‚½ãƒ¼ã‚¹ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        if self.conn:
            self.conn.close()
            self.conn = None
        if os.path.exists(self.db_file):
            try:
                os.remove(self.db_file)
            except OSError as e:
                print(f"Error removing temporary database file {self.db_file}: {e}")

    def __del__(self):
        self.close()

    def debug_data_verification(self): # æ–°è¦è¿½åŠ 
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®å†…å®¹ã‚’ç¢ºèªï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰""" # æ–°è¦è¿½åŠ 
        try: # æ–°è¦è¿½åŠ 
            # ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡Œæ•°ç¢ºèª # æ–°è¦è¿½åŠ 
            count_result = self.conn.execute(f"SELECT COUNT(*) FROM {self.table_name}").fetchone()[0] # æ–°è¦è¿½åŠ 
            print(f"DEBUG: SQLiteãƒ†ãƒ¼ãƒ–ãƒ«ç·è¡Œæ•°: {count_result}") # æ–°è¦è¿½åŠ 
            
            # æœ€åˆã®5è¡Œã‚’è¡¨ç¤º # æ–°è¦è¿½åŠ 
            sample_result = self.conn.execute(f"SELECT * FROM {self.table_name} LIMIT 5").fetchall() # æ–°è¦è¿½åŠ 
            print(f"DEBUG: ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆæœ€åˆã®5è¡Œï¼‰: {sample_result}") # æ–°è¦è¿½åŠ 
            
            # ç‰¹å®šã®æ¤œç´¢å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã®ç¢ºèª # æ–°è¦è¿½åŠ 
            search_result = self.conn.execute(f'SELECT rowid, * FROM {self.table_name} WHERE "å•†å“ç•ªå·" LIKE "%00-012%"').fetchall() # æ–°è¦è¿½åŠ 
            print(f"DEBUG: '00-012'ã‚’å«ã‚€è¡Œ: {search_result}") # æ–°è¦è¿½åŠ 
            
        except Exception as e: # æ–°è¦è¿½åŠ 
            print(f"DEBUG: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}") # æ–°è¦è¿½åŠ 

    def debug_verify_data(self, search_term): # æ–°è¦è¿½åŠ 
        """ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®ç‰¹å®šãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèª""" # æ–°è¦è¿½åŠ 
        try: # æ–°è¦è¿½åŠ 
            result = self.conn.execute( # æ–°è¦è¿½åŠ 
                f'SELECT rowid, "å•†å“ç•ªå·" FROM {self.table_name} WHERE "å•†å“ç•ªå·" LIKE ?', # æ–°è¦è¿½åŠ 
                [f'%{search_term}%'] # æ–°è¦è¿½åŠ 
            ).fetchall() # æ–°è¦è¿½åŠ 
            print(f"DEBUG: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®'{search_term}'ã‚’å«ã‚€è¡Œ: {result}") # æ–°è¦è¿½åŠ 
            return result # æ–°è¦è¿½åŠ 
        except Exception as e: # æ–°è¦è¿½åŠ 
            print(f"DEBUG: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ç¢ºèªã‚¨ãƒ©ãƒ¼: {e}") # æ–°è¦è¿½åŠ 
            return [] # æ–°è¦è¿½åŠ 